# UnReal Backend Setup Guide

This guide will help you set up the Python ML backends required for the UnReal Chrome Extension.

---

## ğŸ“‹ What You Need

- **Python 3.8+** - [Download here](https://www.python.org/downloads/)
- **~3 GB free disk space** - For ML models
- **~3 GB RAM** - For running the servers

---

## ğŸš€ Setup Steps

### Step 1: Open Terminal/Command Prompt

Navigate to the backend folder:

```bash
cd extension/backend
```

### Step 2: Install Python Packages

```bash
pip install -r requirements.txt
```

> â±ï¸ This may take 5-10 minutes on first install.

### Step 3: Start the Servers

You need to run **3 servers** in **3 separate terminal windows**:

---

#### ğŸ–¼ï¸ Terminal 1: Main Server (Image, Video, News Analysis)

```bash
cd extension/backend
python server.py
```

**Expected output:**
```
[ML Backend] Loading model: unreal-social-media-tuned
[ML Backend] Model loaded successfully
INFO:     Uvicorn running on http://0.0.0.0:8000
```

âœ… Server running at: `http://localhost:8000`

---

#### ğŸ“ Terminal 2: Text Detection Server

```bash
cd extension/backend
python text_detector.py
```

**Expected output:**
```
Loading RoBERTa model...
* Running on http://127.0.0.1:8001
```

âœ… Server running at: `http://localhost:8001`

---

#### ğŸµ Terminal 3: Audio Deepfake Detection (Optional)

```bash
cd extension/backend
python audio_detector.py
```

**Expected output:**
```
* Running on http://127.0.0.1:8002
```

âœ… Server running at: `http://localhost:8002`

---

## âœ… Verify Everything Works

Open your browser and visit:

| URL | Expected Response |
|-----|-------------------|
| http://localhost:8000 | `{"status": "running", ...}` |
| http://localhost:8001/health | `{"status": "ok"}` |
| http://localhost:8002/health | `{"status": "ok"}` |

If you see JSON responses, the servers are working! ğŸ‰

---

## ğŸ“ Files Explained

```
backend/
â”œâ”€â”€ server.py          # Main server - image, video, news verification
â”œâ”€â”€ text_detector.py   # AI-generated text detection
â”œâ”€â”€ audio_detector.py  # Audio deepfake detection
â”œâ”€â”€ requirements.txt   # Python packages needed
â”œâ”€â”€ model/             # Pre-trained image detection model
â””â”€â”€ text_model/        # Pre-trained text detection model
```

---

## âš ï¸ Common Issues

### "Module not found" error
```bash
pip install -r requirements.txt
```

### Port already in use
Kill existing process or change port in the Python file.

### Models downloading slowly
First run downloads models from HuggingFace (~500MB). Wait for it to complete.

### CUDA/GPU errors
The backend automatically uses CPU if GPU isn't available. No action needed.

---

## ğŸ”Œ How Extension Connects

The Chrome extension automatically connects to these local servers:
- **Port 8000** â†’ Image & Video analysis
- **Port 8001** â†’ Text analysis  
- **Port 8002** â†’ Audio analysis

No configuration needed - just keep the servers running!

---

## ğŸ’¡ Tips

1. **Keep all 3 terminals open** while using the extension
2. **First analysis is slow** (model warmup), subsequent ones are fast
3. **Restart servers** if you see connection errors in the extension

---

**Need help?** Check the error messages in the terminal windows.
